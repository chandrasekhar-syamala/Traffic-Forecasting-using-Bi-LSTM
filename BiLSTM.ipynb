{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68d5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71817fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def reshape_data(rawdata):\n",
    "    reshaped_tps_df = pd.DataFrame()\n",
    "    reshaped_tps_df['TIME'] = rawdata.time.unique()\n",
    "    for seg in rawdata.segmentID.unique():\n",
    "        column = rawdata[rawdata['segmentID'] == seg][['time','TrafficIndex_GP']].drop_duplicates(subset=['time'])\n",
    "        column.columns = ['TIME', str(seg)]\n",
    "        reshaped_tps_df = reshaped_tps_df.join(column.set_index('TIME'), on='TIME')\n",
    "    #print(reshaped_tps_df.describe());\n",
    "    return reshaped_tps_df\n",
    "\n",
    "def load_data(filepath, start_time, end_time, freq):\n",
    "    rawdata = pd.read_pickle(filepath)\n",
    "    #print(rawdata.head())\n",
    "    matrix = reshape_data(rawdata)\n",
    "    matrix['TIME'] = pd.to_datetime(matrix['TIME']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    dt_idx = pd.date_range(start=start_time, end=end_time, freq=freq)\n",
    "\n",
    "    output = pd.DataFrame(dt_idx)\n",
    "    output.columns = ['TIME']\n",
    "    output['TIME'] = pd.to_datetime(output['TIME']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    output = output.set_index('TIME').join(matrix.set_index('TIME'))\n",
    "    #print(output.describe())\n",
    "    return output\n",
    "\n",
    "def prepare_dataloader(matrix, n_col, seq_len=36, pred_len=12, BATCH_SIZE=32, device='cpu'):\n",
    "    seg = matrix.columns.values\n",
    "    time = matrix.index.values\n",
    "    n_seg = len(seg)\n",
    "    n_time = len(time)\n",
    "    \n",
    "    speedMatrix = matrix.to_numpy()\n",
    "    \n",
    "    data_set = []\n",
    "    label_set = []\n",
    "\n",
    "    for i in range(n_time - seq_len - pred_len):\n",
    "        data = speedMatrix[i : i + seq_len]\n",
    "        \n",
    "        label_data = speedMatrix[i + seq_len: i + seq_len + pred_len, :n_col]\n",
    "        \n",
    "        if np.isnan(np.sum(data[:n_col])).any() | np.isnan(np.sum(label_data)):\n",
    "            pass\n",
    "        else:\n",
    "\n",
    "            data_set.append(data)\n",
    "            label_set.append(label_data)\n",
    "            \n",
    "    data = np.array(data_set)\n",
    "    label = np.array(label_set)\n",
    "\n",
    "    train_ind = int(len(data)* 0.8)\n",
    "    valid_ind = int(len(data) * 0.9)\n",
    "    test_ind = int(len(data) * 1.0)\n",
    "\n",
    "    X_train = data[: train_ind]\n",
    "    X_valid = data[train_ind : valid_ind]\n",
    "    X_test = data[valid_ind : test_ind]\n",
    "    Y_train = label[: train_ind]\n",
    "    Y_valid = label[train_ind : valid_ind]\n",
    "    Y_test = label[valid_ind : test_ind]\n",
    "    X_train = torch.FloatTensor(X_train).to(device)\n",
    "    X_valid = torch.FloatTensor(X_valid).to(device)\n",
    "    X_test = torch.FloatTensor(X_test).to(device)\n",
    "    Y_train = torch.FloatTensor(Y_train).to(device)\n",
    "    Y_valid = torch.FloatTensor(Y_valid).to(device)\n",
    "    Y_test = torch.FloatTensor(Y_test).to(device)\n",
    "\n",
    "    train_dataset = utils.TensorDataset(X_train, Y_train)\n",
    "    valid_dataset = utils.TensorDataset(X_valid, Y_valid)\n",
    "    test_dataset = utils.TensorDataset(X_test, Y_test)\n",
    "\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, drop_last = False)\n",
    "\n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427d7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation\n",
    "class lstm_encoder(nn.Module):\n",
    "    ''' Encodes time-series sequence '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 2):\n",
    "        \n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True,bidirectional=True)\n",
    "        self.l1=nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.l2=nn.Linear(4,2)\n",
    "    def forward(self, x_input):\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(self.num_layers*2, x_input.size(0), self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(self.num_layers*2, x_input.size(0), self.hidden_size).cuda())\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(self.num_layers*2, x_input.size(0), self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(self.num_layers*2, x_input.size(0), self.hidden_size))\n",
    "        \n",
    "        a,(b,c)= self.lstm(x_input, (Hidden_State, Cell_State))\n",
    "        b=b.permute(1,2,0)\n",
    "        c=c.permute(1,2,0)\n",
    "        #print(type(b),b.shape,c.shape)\n",
    "        b=self.l2(b)\n",
    "        c=self.l2(c)\n",
    "        #print(\"dfe\",b.shape)\n",
    "        b=b.permute(2,0,1)\n",
    "        #print(\"dfe\",b.shape)\n",
    "        c=c.permute(2,0,1)\n",
    "        b=b.contiguous()\n",
    "        c=c.contiguous()\n",
    "        lstm_out=self.l1(a)\n",
    "        #print(\"  \",b.shape,c.shape)\n",
    "        self.hidden=tuple((b,c))\n",
    "        #print(self.hidden[0].shape)\n",
    "        return lstm_out, self.hidden\n",
    "\n",
    "class lstm_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers = 2):\n",
    "        \n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)       \n",
    "\n",
    "    def forward(self, x_input, encoder_hidden_states):\n",
    "        lstm_out, self.hidden = self.lstm(x_input.unsqueeze(1), encoder_hidden_states)      \n",
    "        return lstm_out.squeeze(1), self.hidden\n",
    "\n",
    "class LSTM_Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, target_len):\n",
    "        super(LSTM_Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_len = target_len\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #print(\"inpu  shap; \",inputs.shape)\n",
    "        batch_size = inputs.shape[0]\n",
    "        output_feature = inputs.shape[2]\n",
    "        outputs = None\n",
    "    \n",
    "        encoder_output, encoder_hidden = self.encoder(inputs)\n",
    "        decoder_input = inputs[:, -1, :]\n",
    "        decoder_hidden = encoder_hidden\n",
    "                \n",
    "        for t in range(self.target_len): \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            if outputs is None:\n",
    "                outputs = decoder_output.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((decoder_output.unsqueeze(1), outputs), 1)\n",
    "            decoder_input = decoder_output\n",
    "        return outputs\n",
    "\n",
    "def TrainModel_LSTM_Seq2Seq(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, min_delta, use_gpu, patience):\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "\n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "       \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        for data in train_dataloader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "                \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            model.train()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            total_train_loss += loss_train.data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for data in valid_dataloader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "                \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "  \n",
    "            outputs_val= model(inputs)\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels))\n",
    "            total_valid_loss += loss_valid.data\n",
    "\n",
    "        avg_losses_epoch_train = total_train_loss / float(len(train_dataloader))\n",
    "        avg_losses_epoch_valid = total_valid_loss / float(len(valid_dataloader))\n",
    "\n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                    epoch, \\\n",
    "                    np.around(avg_losses_epoch_train.cpu(), decimals=8),\\\n",
    "                    np.around(avg_losses_epoch_valid.cpu(), decimals=8),\\\n",
    "                    np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                    is_best_model) )\n",
    "        pre_time = cur_time\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01e23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "INPUT_LEN = 36\n",
    "PRED_LEN = 12\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 100\n",
    "MIN_DELTA = 5e-4\n",
    "PATIENCE = 25\n",
    "\n",
    "BASELINE_MODEL_INPUT_DIMENSION = 87\n",
    "BASELINE_MODEL_HIDDEN_DIMENSION = 87\n",
    "BASELINE_MODEL_OUTPUT_DIMENSION = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900e3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e32dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa59b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = load_data(\"./tps_df.pkl\", \"2020-01-01 00:00:00.000\", \"2020-05-31 23:45:00.000\", freq=\"15min\")\n",
    "#print(data_matrix.head())\n",
    "input_dim = data_matrix.shape[-1]\n",
    "\n",
    "train_dataloader, valid_dataloader, _ = prepare_dataloader(data_matrix, input_dim, BATCH_SIZE=BATCH_SIZE, seq_len=INPUT_LEN, pred_len=PRED_LEN, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529b3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = lstm_encoder(input_size=BASELINE_MODEL_INPUT_DIMENSION, hidden_size=BASELINE_MODEL_HIDDEN_DIMENSION)\n",
    "decoder = lstm_decoder(input_size=BASELINE_MODEL_HIDDEN_DIMENSION, hidden_size=BASELINE_MODEL_OUTPUT_DIMENSION)\n",
    "seq2seq_model = LSTM_Seq2Seq(encoder, decoder, PRED_LEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b288a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.9035462141036987, valid_loss: 0.868556559085846, time: [45.53], best model: 1\n",
      "Epoch: 1, train_loss: 0.645154595375061, valid_loss: 0.43930259346961975, time: [48.97], best model: 1\n",
      "Epoch: 2, train_loss: 0.26755568385124207, valid_loss: 0.1706928163766861, time: [51.21], best model: 1\n",
      "Epoch: 3, train_loss: 0.10830829292535782, valid_loss: 0.07366997003555298, time: [55.1], best model: 1\n",
      "Epoch: 4, train_loss: 0.05329104885458946, valid_loss: 0.0364966094493866, time: [51.37], best model: 1\n",
      "Epoch: 5, train_loss: 0.031159810721874237, valid_loss: 0.018832620233297348, time: [51.09], best model: 1\n",
      "Epoch: 6, train_loss: 0.02098405919969082, valid_loss: 0.01005691010504961, time: [61.61], best model: 1\n",
      "Epoch: 7, train_loss: 0.016267169266939163, valid_loss: 0.005771350115537643, time: [51.42], best model: 1\n",
      "Epoch: 8, train_loss: 0.014143779873847961, valid_loss: 0.0037501798942685127, time: [47.12], best model: 1\n",
      "Epoch: 9, train_loss: 0.013199100270867348, valid_loss: 0.002929429989308119, time: [54.69], best model: 1\n",
      "Epoch: 10, train_loss: 0.012532380409538746, valid_loss: 0.00249279011040926, time: [46.07], best model: 0\n",
      "Epoch: 11, train_loss: 0.012004739604890347, valid_loss: 0.0023477000650018454, time: [45.11], best model: 1\n",
      "Epoch: 12, train_loss: 0.011521520093083382, valid_loss: 0.0021774200722575188, time: [46.04], best model: 0\n",
      "Epoch: 13, train_loss: 0.01097435038536787, valid_loss: 0.0019418400479480624, time: [51.08], best model: 0\n",
      "Epoch: 14, train_loss: 0.010445769876241684, valid_loss: 0.0018147400114685297, time: [53.72], best model: 1\n",
      "Epoch: 15, train_loss: 0.00999549962580204, valid_loss: 0.001770589966326952, time: [48.48], best model: 0\n",
      "Epoch: 16, train_loss: 0.009606740437448025, valid_loss: 0.0015866400208324194, time: [48.33], best model: 0\n",
      "Epoch: 17, train_loss: 0.009208249859511852, valid_loss: 0.0014087599702179432, time: [47.91], best model: 0\n",
      "Epoch: 18, train_loss: 0.008833060041069984, valid_loss: 0.0013509199488908052, time: [47.45], best model: 0\n",
      "Epoch: 19, train_loss: 0.008544850163161755, valid_loss: 0.0012615099549293518, time: [50.06], best model: 1\n",
      "Epoch: 20, train_loss: 0.00831609033048153, valid_loss: 0.0012366200098767877, time: [52.28], best model: 0\n",
      "Epoch: 21, train_loss: 0.008079149760305882, valid_loss: 0.0010858499445021152, time: [52.17], best model: 0\n",
      "Epoch: 22, train_loss: 0.007861729711294174, valid_loss: 0.0014946300070732832, time: [49.97], best model: 0\n",
      "Epoch: 23, train_loss: 0.00766419991850853, valid_loss: 0.0011826599948108196, time: [45.66], best model: 0\n",
      "Epoch: 24, train_loss: 0.007471390068531036, valid_loss: 0.0009681900264695287, time: [49.61], best model: 0\n",
      "Epoch: 25, train_loss: 0.007297940086573362, valid_loss: 0.0011581199942156672, time: [48.74], best model: 0\n",
      "Epoch: 26, train_loss: 0.007140779867768288, valid_loss: 0.0009038600255735219, time: [50.69], best model: 0\n",
      "Epoch: 27, train_loss: 0.006994340103119612, valid_loss: 0.000905209977645427, time: [49.59], best model: 0\n",
      "Epoch: 28, train_loss: 0.006865739822387695, valid_loss: 0.0010376600548624992, time: [54.81], best model: 0\n",
      "Epoch: 29, train_loss: 0.006734679918736219, valid_loss: 0.000976660056039691, time: [51.74], best model: 0\n",
      "Epoch: 30, train_loss: 0.006627319846302271, valid_loss: 0.0009373599896207452, time: [50.96], best model: 0\n",
      "Epoch: 31, train_loss: 0.006513080094009638, valid_loss: 0.0011234000558033586, time: [47.19], best model: 0\n",
      "Epoch: 32, train_loss: 0.006423070095479488, valid_loss: 0.0009430400095880032, time: [46.83], best model: 0\n",
      "Epoch: 33, train_loss: 0.006327370181679726, valid_loss: 0.0009263699757866561, time: [46.07], best model: 0\n",
      "Epoch: 34, train_loss: 0.006250040140002966, valid_loss: 0.0010156199568882585, time: [44.76], best model: 0\n",
      "Epoch: 35, train_loss: 0.006168319843709469, valid_loss: 0.0010148800211027265, time: [44.56], best model: 0\n",
      "Epoch: 36, train_loss: 0.006105020176619291, valid_loss: 0.0009407000034116209, time: [45.14], best model: 0\n",
      "Epoch: 37, train_loss: 0.006042439956218004, valid_loss: 0.0009530300158075988, time: [44.44], best model: 0\n",
      "Epoch: 38, train_loss: 0.005974640138447285, valid_loss: 0.00085678999312222, time: [43.94], best model: 0\n",
      "Early Stopped at Epoch: 39\n"
     ]
    }
   ],
   "source": [
    "seq2seq_best_model = TrainModel_LSTM_Seq2Seq(seq2seq_model, train_dataloader, valid_dataloader, num_epochs=NUM_EPOCHS, \n",
    "                                              learning_rate=LEARNING_RATE, \n",
    "                                              min_delta=MIN_DELTA, \n",
    "                                              use_gpu=use_gpu,\n",
    "                                              patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333f0e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\\tps_1.pkl\n",
      "2020-06-02 06:15:00 2020-06-02 09:00:00\n",
      "test_data\\tps_2.pkl\n",
      "2020-06-03 07:15:00 2020-06-03 10:00:00\n",
      "test_data\\tps_3.pkl\n",
      "2020-06-04 08:15:00 2020-06-04 11:00:00\n",
      "test_data\\tps_4.pkl\n",
      "2020-06-05 09:15:00 2020-06-05 12:00:00\n",
      "test_data\\tps_5.pkl\n",
      "2020-06-06 10:15:00 2020-06-06 13:00:00\n",
      "test_data\\tps_6.pkl\n",
      "2020-06-07 11:15:00 2020-06-07 14:00:00\n",
      "test_data\\tps_7.pkl\n",
      "2020-06-08 12:15:00 2020-06-08 15:00:00\n",
      "test_data\\tps_8.pkl\n",
      "2020-06-09 13:15:00 2020-06-09 16:00:00\n",
      "test_data\\tps_9.pkl\n",
      "2020-06-10 14:15:00 2020-06-10 17:00:00\n",
      "test_data\\tps_10.pkl\n",
      "2020-06-11 15:15:00 2020-06-11 18:00:00\n",
      "test_data\\tps_11.pkl\n",
      "2020-06-12 16:15:00 2020-06-12 19:00:00\n",
      "test_data\\tps_12.pkl\n",
      "2020-06-13 17:15:00 2020-06-13 20:00:00\n",
      "test_data\\tps_13.pkl\n",
      "2020-06-14 18:15:00 2020-06-14 21:00:00\n",
      "test_data\\tps_14.pkl\n",
      "2020-06-15 19:15:00 2020-06-15 22:00:00\n",
      "test_data\\tps_15.pkl\n",
      "2020-06-16 20:15:00 2020-06-16 23:00:00\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step1: read and reshape data\n",
    "Step2: feed into trained model\n",
    "Step3: convert output to JSON file\n",
    "Here we take one testing data as an example to convert it to JSON file.\n",
    "In this challenge, you should convert all 15 predicting results to one JSON file.\n",
    "Please check https://colab.research.google.com/drive/1Hkt3kQuh7WzwUTnLgKCcvfPAV1CUK8lF?usp=sharing for more information of the expected result.\n",
    "'''\n",
    "test_files=[]\n",
    "for i in range(1,16):\n",
    "    test_files.append(\"tps_\"+str(i)+\".pkl\")\n",
    "out_cols = ['11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
    "       '35', '36', '37', '38', '39', '40', '42', '43', '44', '45', '46', '47',\n",
    "       '49', '50', '51', '52', '53', '54', '55', '58', '59', '60', '61', '62',\n",
    "       '63', '64', '65', '66', '67', '68', '69', '70', '73', '74', '75', '76',\n",
    "       '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n",
    "       '89', '90', '91', '92', '93', '94', '95', '96', '97', '99', '100',\n",
    "       '102', '103', '104', '106']\n",
    "\n",
    "horizon = {'tps_1.pkl':['2020-06-02 06:15:00', '2020-06-02 09:00:00'],\n",
    "           'tps_2.pkl':['2020-06-03 07:15:00', '2020-06-03 10:00:00'],\n",
    "           'tps_3.pkl':['2020-06-04 08:15:00', '2020-06-04 11:00:00'],\n",
    "           'tps_4.pkl':['2020-06-05 09:15:00', '2020-06-05 12:00:00'],\n",
    "           'tps_5.pkl':['2020-06-06 10:15:00', '2020-06-06 13:00:00'],\n",
    "           'tps_6.pkl':['2020-06-07 11:15:00', '2020-06-07 14:00:00'],\n",
    "           'tps_7.pkl':['2020-06-08 12:15:00', '2020-06-08 15:00:00'],\n",
    "           'tps_8.pkl':['2020-06-09 13:15:00', '2020-06-09 16:00:00'],\n",
    "           'tps_9.pkl':['2020-06-10 14:15:00', '2020-06-10 17:00:00'],\n",
    "           'tps_10.pkl':['2020-06-11 15:15:00', '2020-06-11 18:00:00'],\n",
    "           'tps_11.pkl':['2020-06-12 16:15:00', '2020-06-12 19:00:00'],\n",
    "           'tps_12.pkl':['2020-06-13 17:15:00', '2020-06-13 20:00:00'],\n",
    "           'tps_13.pkl':['2020-06-14 18:15:00', '2020-06-14 21:00:00'],\n",
    "           'tps_14.pkl':['2020-06-15 19:15:00', '2020-06-15 22:00:00'],\n",
    "           'tps_15.pkl':['2020-06-16 20:15:00', '2020-06-16 23:00:00'],\n",
    "           }\n",
    "out_df = pd.DataFrame(columns = out_cols)\n",
    "testcase=1;\n",
    "for test_file in test_files:\n",
    "  print (os.path.join('test_data',test_file))\n",
    "  tps_1_raw = pd.read_pickle(os.path.join('test_data',test_file))\n",
    "  #print (tps_1_raw.head())\n",
    "  \n",
    "  \n",
    "  reshaped_tps_df = reshape_data(tps_1_raw)\n",
    "  reshaped_tps_df = reshaped_tps_df.set_index('TIME')\n",
    "  reshaped_tps_df.to_csv(\"test\"+str(testcase)+\".csv\")\n",
    "  testcase=testcase+1\n",
    "  reshaped_tps_value = reshaped_tps_df.values\n",
    "  reshaped_tps_value = np.expand_dims(reshaped_tps_value, axis=0)\n",
    "  reshaped_tps_value = torch.from_numpy(reshaped_tps_value).float().to(device)\n",
    "\n",
    "  seq2seq_out = seq2seq_best_model(reshaped_tps_value).squeeze(0)\n",
    "\n",
    "  output_1 = pd.DataFrame(seq2seq_out.cpu().detach().numpy())\n",
    "  \n",
    "  # output_1.index = pd.date_range(start='2020-06-02 06:15:00', end='2020-06-02 09:00:00', freq='15min').astype(int) / 10**9\n",
    "  st = horizon[test_file][0]; et = horizon[test_file][1]\n",
    "  print (st, et)\n",
    "  output_1.index = pd.date_range(start=st, end=et, freq='15min').astype(int) / 10**9\n",
    "  output_1.columns = reshaped_tps_df.columns\n",
    "  output_1.to_csv(\"output.csv\")\n",
    "  out_df = pd.concat([out_df,output_1])\n",
    "\n",
    "# out_df.reset_index(inplace=True)\n",
    "out_df.to_json('./Bi_lstm_traffic_forecasting_result_all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
